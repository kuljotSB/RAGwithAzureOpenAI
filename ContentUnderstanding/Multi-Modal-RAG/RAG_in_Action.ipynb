{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0401f0a",
   "metadata": {},
   "source": [
    "## Multi-Modal RAG with Azure AI Content Understanding - In Action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae66ab3",
   "metadata": {},
   "source": [
    "![rag_in_action](./Assets/rag_in_action.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58672a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c38f43",
   "metadata": {},
   "source": [
    "### Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c41056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Azure OpenAI Configurations\n",
    "azure_ai_endpoint = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    "azure_ai_api_key = os.getenv(\"AZURE_AI_API_KEY\")\n",
    "embedding_model_name = os.getenv(\"EMBEDDING_MODEL_NAME\")\n",
    "chat_model_name = os.getenv(\"CHAT_MODEL_NAME\")\n",
    "\n",
    "# Azure Search Service Configurations\n",
    "search_service_endpoint = os.getenv(\"SEARCH_SERVICE_ENDPOINT\")\n",
    "search_service_api_key = os.getenv(\"SEARCH_SERVICE_API_KEY\")\n",
    "search_service_index_name = os.getenv(\"SEARCH_SERVICE_INDEX_NAME\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08159da",
   "metadata": {},
   "source": [
    "### Creating Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3310933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "openai_client = AzureOpenAI(\n",
    "    api_key = os.getenv(\"AZURE_AI_API_KEY\"),\n",
    "    api_version = \"2024-02-15-preview\",\n",
    "    azure_endpoint = os.getenv(\"AZURE_AI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e728e01e",
   "metadata": {},
   "source": [
    "### Creating a Function for Generating Vector Embeddings using Azure OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "def generate_embeddings(text, embedding_model_name):\n",
    "    response = openai_client.embeddings.create(\n",
    "        input=text,\n",
    "        model=embedding_model_name\n",
    "    )\n",
    "\n",
    "    embeddings = response.model_dump()\n",
    "\n",
    "    return embeddings[\"data\"][0][\"embedding\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d0986e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Queries to try out:\n",
    "1. tell me something about BMW Circularity Project\n",
    "2. Tell me something about BMW's forwardism strategy\n",
    "3. Tell me something about BMW's sustainable natural rubber initiative\n",
    "4. Tell me through BMW's sustainability journey from 1973 to 2030\n",
    "\"\"\"\n",
    "\n",
    "user_query = \"tell me something about BMW Circularity Project\"\n",
    "vectorised_user_query = generate_embeddings(user_query, embedding_model_name)\n",
    "print(vectorised_user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4bb8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de43069",
   "metadata": {},
   "source": [
    "### Sending API call to the Search Index to Build Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "url = f\"{search_service_endpoint}/indexes/{search_service_index_name}/docs/search?api-version=2023-11-01\"\n",
    "    \n",
    "headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": search_service_api_key\n",
    "    }\n",
    "    \n",
    "body =   {\n",
    "        \"count\": True,\n",
    "        \"select\": \"content_text\",\n",
    "        \"vectorQueries\": [\n",
    "            {\n",
    "                \"vector\": vectorised_user_query,\n",
    "                \"k\": 10,\n",
    "                \"fields\": \"content_embedding\",\n",
    "                \"kind\": \"vector\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "response = requests.post(url, headers=headers, data=json.dumps(body))\n",
    "documents = response.json()['value']\n",
    "\n",
    "for doc in documents:\n",
    "    context.append(dict(\n",
    "        {\n",
    "            \"chunk\": doc['content_text'],\n",
    "            \"score\": doc['@search.score']\n",
    "            \n",
    "        }\n",
    "    ))\n",
    "    \n",
    "for doc in context:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b75fbc7",
   "metadata": {},
   "source": [
    "### Setting the System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31745769",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a professional RAG-based assistant whose context comes exclusively from a database in Azure AI Search\n",
    "\n",
    "Always follow these rules:\n",
    "\n",
    "1. Answer strictly from the context provided. Do not invent, assume, or add details outside the given context.\n",
    "2. If no relevant information is available in the context, politely say so.\n",
    "3. Do not include any external links, citations, or references unless they are explicitly present in the context object.\n",
    "4. Context format: The system will pass a Python list of objects, each containing:\n",
    "   {\n",
    "     \"chunk\": \"the content (text, JSON, transcript, or description)\",\n",
    "     \"score\": \"the relevancy score\"\n",
    "   }\n",
    "   These are the top matches based on cosine similarity with the user query.\n",
    "5. Style & tone:\n",
    "   - Respond in a professional, natural way, as if conversing with a human.\n",
    "   - Structure answers clearly and concisely.\n",
    "   - Do not reveal that retrieval-augmented generation (RAG) is being used under the hood.\n",
    "   - If the context contains a field such as 'url', 'video_url', or 'image_url', include it as a clickable hyperlink in your response, but do not fabricate or assume URLs.\n",
    "\n",
    "Your role is to act like a knowledgeable human assistant who can reference the provided information smoothly and contextually, across any modality (text, image, video, or review description).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f83d0e",
   "metadata": {},
   "source": [
    "### Calling GPT Engine for Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a295e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = f\"\"\" The user query is: {user_query}\n",
    "              the context is: {context} \"\"\"\n",
    "\n",
    "chat_completions_response = openai_client.chat.completions.create(\n",
    "    model = chat_model_name,\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_query}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(chat_completions_response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
