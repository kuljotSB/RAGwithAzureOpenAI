{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f06d539",
   "metadata": {},
   "source": [
    "## Custom Analyzer with Azure AI Content Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6b730",
   "metadata": {},
   "source": [
    "![image](./Assets/image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0105cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e840c",
   "metadata": {},
   "source": [
    "### Setting up the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f56105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CONTENT_UNDERSTANDING_ENDPOINT = os.getenv(\"CONTENT_UNDERSTANDING_ENDPOINT\").strip().rstrip('/')\n",
    "CONTENT_UNDERSTANDING_API_KEY = os.getenv(\"CONTENT_UNDERSTANDING_API_KEY\")\n",
    "CUSTOM_ANALYZER_NAME = os.getenv(\"CUSTOM_ANALYZER_NAME\")\n",
    "\n",
    "print(\"Endpoint:\", CONTENT_UNDERSTANDING_ENDPOINT)\n",
    "print(\"API Key:\", CONTENT_UNDERSTANDING_API_KEY)\n",
    "print(\"Custom Analyzer Name:\", CUSTOM_ANALYZER_NAME)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9ce695",
   "metadata": {},
   "source": [
    "### Running Custom Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prebuilt_document_analyzer_url = f\"{CONTENT_UNDERSTANDING_ENDPOINT}/contentunderstanding/analyzers/{CUSTOM_ANALYZER_NAME}:analyze?api-version=2025-05-01-preview\"\n",
    "\n",
    "document_url = \"https://github.com/kuljotSB/RAGwithAzureOpenAI/raw/refs/heads/main/ContentUnderstanding/Custom_Analyzer/invoices/invoice.pdf\"\n",
    "\n",
    "body = {\n",
    "    \"url\": document_url\n",
    "}\n",
    "\n",
    "document_analysis_result = {}\n",
    "\n",
    "try:\n",
    "    headers = {\n",
    "                \"Content-Type\": \"application/json\",\n",
    "                \"Ocp-Apim-Subscription-Key\": CONTENT_UNDERSTANDING_API_KEY\n",
    "            }\n",
    "\n",
    "    response = requests.post(prebuilt_document_analyzer_url, headers=headers, json=body)\n",
    "    response.raise_for_status()\n",
    "    result = response.json()\n",
    "    analysis_id = result.get(\"id\")\n",
    "    print(\"Analysis ID:\", analysis_id)\n",
    "\n",
    "    # Using the analysis ID to get results; polling until the analysis is complete\n",
    "    get_result_url = f\"{CONTENT_UNDERSTANDING_ENDPOINT}/contentunderstanding/analyzerResults/{analysis_id}?api-version=2025-05-01-preview\"\n",
    "    \n",
    "    headers = {\n",
    "        \"Ocp-Apim-Subscription-Key\": CONTENT_UNDERSTANDING_API_KEY\n",
    "    }\n",
    "    analysis_status = \"Running\"\n",
    "    while analysis_status == \"Running\":\n",
    "        status_response = requests.get(get_result_url, headers=headers)\n",
    "        status_response.raise_for_status()\n",
    "        status_result = status_response.json()\n",
    "        analysis_status = status_result.get(\"status\")\n",
    "        print(\"Current Analysis Status:\", analysis_status)\n",
    "        if analysis_status == \"Running\":\n",
    "            import time\n",
    "            time.sleep(1)  # Wait before polling again\n",
    "    result_response = requests.get(get_result_url, headers=headers)\n",
    "    result_response.raise_for_status()\n",
    "    document_analysis_result = result_response.json()\n",
    "    print(\"Document Analysis Result:\", document_analysis_result)\n",
    "\n",
    "except requests.RequestException as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c12cfb",
   "metadata": {},
   "source": [
    "### Displaying Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e791fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "def _hr(char=\"─\", width=80):\n",
    "    return char * width\n",
    "\n",
    "def _h(text: str, width=80):\n",
    "    pad = \" \" * 2\n",
    "    line = f\"{pad}{text.strip()} \"\n",
    "    return f\"{_hr('=')} \\n{line}\\n{_hr('=')}\"\n",
    "\n",
    "def _subh(text: str):\n",
    "    return f\"\\n{text}\\n{_hr()}\"\n",
    "\n",
    "def _kv(k: str, v: Any, k_width=22):\n",
    "    k = (k or \"\").strip()\n",
    "    if isinstance(v, (dict, list)):\n",
    "        v_str = json.dumps(v, indent=2, ensure_ascii=False)\n",
    "    else:\n",
    "        v_str = \"\" if v is None else str(v)\n",
    "    return f\"{k:<{k_width}} : {v_str}\"\n",
    "\n",
    "def _wrap_block(text: str, width=100, indent=\"    \"):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    wrapped = textwrap.fill(text, width=width)\n",
    "    return textwrap.indent(wrapped, indent)\n",
    "\n",
    "def display_document_analyzer_content_understanding_result(\n",
    "    analysis_result: Dict[str, Any],\n",
    "    save_markdown_path: Optional[str] = None,\n",
    "    max_markdown_chars: int = 1200,\n",
    "    width: int = 100,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Pretty-prints Azure Content Understanding 'prebuilt-documentAnalyzer' result\n",
    "    and optionally writes extracted Markdown to a file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    analysis_result : dict\n",
    "        The JSON-decoded response you printed as \"Analysis Result\".\n",
    "    save_markdown_path : str | None\n",
    "        If provided (e.g., 'analysis.md'), concatenated markdown from all contents\n",
    "        will be written to this path.\n",
    "    max_markdown_chars : int\n",
    "        Truncate console preview of markdown to this many characters (file is not truncated).\n",
    "    width : int\n",
    "        Wrap width for console output.\n",
    "    \"\"\"\n",
    "    # top-level\n",
    "    print(_h(\"Content Understanding • Analysis Summary\", width))\n",
    "    print(_kv(\"Analysis ID\", analysis_result.get(\"id\")))\n",
    "    print(_kv(\"Status\", analysis_result.get(\"status\")))\n",
    "\n",
    "    result = (analysis_result or {}).get(\"result\", {})\n",
    "    usage = (analysis_result or {}).get(\"usage\", {})\n",
    "    tokens = usage.get(\"tokens\", {}) if isinstance(usage, dict) else {}\n",
    "\n",
    "    print(_subh(\"Analyzer Info\"))\n",
    "    print(_kv(\"Analyzer ID\", result.get(\"analyzerId\")))\n",
    "    print(_kv(\"API Version\", result.get(\"apiVersion\")))\n",
    "    created_at = result.get(\"createdAt\")\n",
    "    try:\n",
    "        created_at_local = (\n",
    "            datetime.fromisoformat(created_at.replace(\"Z\", \"+00:00\")).astimezone().isoformat()\n",
    "            if created_at else None\n",
    "        )\n",
    "    except Exception:\n",
    "        created_at_local = created_at\n",
    "    print(_kv(\"Created At (UTC)\", created_at))\n",
    "    print(_kv(\"Created At (local)\", created_at_local))\n",
    "    warnings = result.get(\"warnings\") or []\n",
    "    print(_kv(\"Warnings\", f\"{len(warnings)}\"))\n",
    "\n",
    "    print(_subh(\"Usage\"))\n",
    "    # note: the API you showed returns floats for tokens; just print raw\n",
    "    for k in (\"contextualization\", \"input\", \"output\"):\n",
    "        if k in tokens:\n",
    "            print(_kv(f\"Tokens.{k}\", tokens.get(k)))\n",
    "\n",
    "    # contents\n",
    "    contents = result.get(\"contents\") or []\n",
    "    print(_subh(f\"Contents ({len(contents)})\"))\n",
    "\n",
    "    combined_md_parts = []\n",
    "    for idx, item in enumerate(contents, start=1):\n",
    "        kind = item.get(\"kind\")\n",
    "        sp = item.get(\"startPageNumber\")\n",
    "        ep = item.get(\"endPageNumber\")\n",
    "        print(_hr())\n",
    "        print(f\"[Content #{idx}] kind={kind}  pages={sp}–{ep}\")\n",
    "\n",
    "        # Fields block (generic)\n",
    "        fields = (item.get(\"fields\") or {})\n",
    "        if fields:\n",
    "            print(\"• Fields:\")\n",
    "            for fname, fval in fields.items():\n",
    "                if isinstance(fval, dict):\n",
    "                    ftype = fval.get(\"type\")\n",
    "                    vstr = fval.get(\"valueString\") or fval.get(\"valueNumber\") or fval.get(\"valueBoolean\") or fval.get(\"valueArray\") or fval.get(\"valueObject\")\n",
    "                    # fall back to full dict if none of the canonical keys exist\n",
    "                    if vstr is None:\n",
    "                        vstr = fval\n",
    "                    print(_wrap_block(f\"  - {fname} ({ftype}): {vstr}\", width))\n",
    "                else:\n",
    "                    print(_wrap_block(f\"  - {fname}: {fval}\", width))\n",
    "\n",
    "        # Markdown preview\n",
    "        md = item.get(\"markdown\") or \"\"\n",
    "        combined_md_parts.append(md)\n",
    "        preview = md.strip()\n",
    "        preview_trunc = (preview[:max_markdown_chars] + \" … [truncated]\") if len(preview) > max_markdown_chars else preview\n",
    "        print(\"• Markdown Preview:\")\n",
    "        print(_wrap_block(preview_trunc, width))\n",
    "\n",
    "    # Save concatenated markdown if requested\n",
    "    if save_markdown_path:\n",
    "        all_md = \"\\n\\n---\\n\\n\".join(part for part in combined_md_parts if part)\n",
    "        out_path = Path(save_markdown_path)\n",
    "        out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        out_path.write_text(all_md, encoding=\"utf-8\")\n",
    "        print(_subh(\"Files\"))\n",
    "        print(_kv(\"Markdown saved\", str(out_path.resolve())))\n",
    "\n",
    "display_document_analyzer_content_understanding_result(document_analysis_result, save_markdown_path=\"document_analysis.md\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
