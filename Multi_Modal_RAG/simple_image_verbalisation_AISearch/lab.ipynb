{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1a82cd4",
   "metadata": {},
   "source": [
    "## Azure AI Search Multi-Modal RAG - Simple Image Verbalisation Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabb5ca1",
   "metadata": {},
   "source": [
    "![simple_image_verbalisation](./Assets/simple_image_verbalisation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949beff2",
   "metadata": {},
   "source": [
    "### Installing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d87004",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai PyMuPDF requests python-dotenv matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd2da1",
   "metadata": {},
   "source": [
    "### Loading Variables from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2633af2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "key = os.getenv(\"AZURE_SEARCH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743ac87",
   "metadata": {},
   "source": [
    "### Creating Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c98d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=azure_openai_endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23928dcc",
   "metadata": {},
   "source": [
    "### Creating the Embedding Generator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(client, text):\n",
    "    embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "    \n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model = embedding_model\n",
    "    )\n",
    "    \n",
    "    embeddings=response.model_dump()\n",
    "    return embeddings['data'][0]['embedding']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6469ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"can you tell me something about the sustainability initiatives at BMW?\"\n",
    "vectorised_user_query = generate_embeddings(azure_openai_client, user_query)\n",
    "print(vectorised_user_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c954881",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0042cb",
   "metadata": {},
   "source": [
    "### Sending API Call to the Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebe186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "url = f\"{service_endpoint}/indexes/{index_name}/docs/search?api-version=2023-11-01\"\n",
    "    \n",
    "headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": key\n",
    "    }\n",
    "    \n",
    "body =   {\n",
    "        \"count\": True,\n",
    "        \"select\": \"document_title, content_text, locationMetadata, image_document_id\",\n",
    "        \"vectorQueries\": [\n",
    "            {\n",
    "                \"vector\": vectorised_user_query,\n",
    "                \"k\": 10,\n",
    "                \"fields\": \"content_embedding\",\n",
    "                \"kind\": \"vector\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "response = requests.post(url, headers=headers, data=json.dumps(body))\n",
    "documents = response.json()['value']\n",
    "\n",
    "for doc in documents:\n",
    "    context.append(dict(\n",
    "        {\n",
    "            \"document_title\": doc['document_title'],\n",
    "            \"chunk\": doc['content_text'],\n",
    "            \"score\": doc['@search.score'],\n",
    "            \"locationMetadata\": doc['locationMetadata'] if 'locationMetadata' in doc else None,\n",
    "            \"image_document_id\": doc['image_document_id'] if 'image_document_id' in doc else None\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "for doc in context:\n",
    "    print(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b143bf",
   "metadata": {},
   "source": [
    "### Function for locating and displaying context in the PDF docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50cc062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "from PIL import Image, ImageDraw\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def highlight_pdf_chunk(\n",
    "    document_title: str,\n",
    "    storage_account_url: str,\n",
    "    content_text: str = None,\n",
    "    location_metadata: dict = None,\n",
    "    download_dir: str = \".\",\n",
    "    zoom: float = 2.0\n",
    "):\n",
    "    def get_clean_text(text: str) -> str:\n",
    "        \"\"\"\n",
    "        Cleans the text for reliable search:\n",
    "        - Removes escape characters\n",
    "        - Truncates at the first newline (to avoid malformed extra content)\n",
    "        - Strips extra whitespace\n",
    "        \"\"\"\n",
    "        return text.split('\\n')[2].replace('\\r', '').strip()\n",
    "\n",
    "    # Construct download URL and local path\n",
    "    pdf_url = f\"{storage_account_url.rstrip('/')}/{document_title}\"\n",
    "    print(f\"[INFO] Downloading PDF from: {pdf_url}\")\n",
    "\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(download_dir, document_title)\n",
    "\n",
    "    # Download the PDF if it doesn't already exist\n",
    "    if not os.path.exists(pdf_path):\n",
    "        try:\n",
    "            response = requests.get(pdf_url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            if not response.content.startswith(b'%PDF'):\n",
    "                raise ValueError(\"Downloaded file is not a valid PDF.\")\n",
    "\n",
    "            with open(pdf_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"[INFO] PDF saved to: {pdf_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to download or save PDF: {e}\")\n",
    "            return\n",
    "\n",
    "    # Open the PDF\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to open PDF with PyMuPDF: {e}\")\n",
    "        return\n",
    "\n",
    "    img = None\n",
    "    title = \"\"\n",
    "\n",
    "    # Highlight via bounding box metadata\n",
    "    if location_metadata:\n",
    "        try:\n",
    "            page_number = location_metadata[\"pageNumber\"] - 1  # 0-based indexing\n",
    "            page = doc.load_page(page_number)\n",
    "\n",
    "            bounding_poly = json.loads(location_metadata[\"boundingPolygons\"])\n",
    "            x_vals = [pt[\"x\"] for pt in bounding_poly[0]]\n",
    "            y_vals = [pt[\"y\"] for pt in bounding_poly[0]]\n",
    "            bbox = (min(x_vals), min(y_vals), max(x_vals), max(y_vals))\n",
    "\n",
    "            mat = fitz.Matrix(zoom, zoom)\n",
    "            pix = page.get_pixmap(matrix=mat)\n",
    "            img = Image.open(BytesIO(pix.tobytes(\"png\")))\n",
    "\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            scaled_bbox = tuple([v * zoom for v in bbox])\n",
    "            draw.rectangle(scaled_bbox, outline=\"red\", width=4)\n",
    "\n",
    "            title = f\"{document_title} - Page {page_number + 1} [via bounding box]\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to highlight using location metadata: {e}\")\n",
    "            doc.close()\n",
    "            return\n",
    "\n",
    "    # Highlight via text search\n",
    "    elif content_text:\n",
    "        clean_text = get_clean_text(content_text)\n",
    "        \n",
    "\n",
    "        if not clean_text:\n",
    "            \n",
    "            doc.close()\n",
    "            return\n",
    "\n",
    "        found = False\n",
    "        for page_number in range(len(doc)):\n",
    "            page = doc[page_number]\n",
    "            instances = page.search_for(clean_text, quads=True)\n",
    "            if instances:\n",
    "                mat = fitz.Matrix(zoom, zoom)\n",
    "                pix = page.get_pixmap(matrix=mat)\n",
    "                img = Image.open(BytesIO(pix.tobytes(\"png\")))\n",
    "                draw = ImageDraw.Draw(img)\n",
    "\n",
    "                for quad in instances:\n",
    "                    rect = quad.rect\n",
    "                    scaled = [\n",
    "                        rect.x0 * zoom,\n",
    "                        rect.y0 * zoom,\n",
    "                        rect.x1 * zoom,\n",
    "                        rect.y1 * zoom,\n",
    "                    ]\n",
    "                    draw.rectangle(scaled, outline=\"blue\", width=4)\n",
    "\n",
    "                title = f\"{document_title} - Page {page_number + 1} [via text match]\"\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            doc.close()\n",
    "            return\n",
    "\n",
    "    else:\n",
    "        print(\"[WARNING] Neither location_metadata nor content_text was provided.\")\n",
    "        doc.close()\n",
    "        return\n",
    "\n",
    "    # Display the result\n",
    "    if img:\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"[ERROR] No image was generated.\")\n",
    "\n",
    "    doc.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56ab2fb",
   "metadata": {},
   "source": [
    "### Calling GPT Engine For Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450325fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\"You are meant to behave as a RAG chatbot that derives its context from a database stored in Azure AI Search Solution.\n",
    "please answer strictly from the context from the database provided and if you dont have an answer please politely say so. dont include any extra \n",
    "information that is not in the context and dont include links as well.\n",
    "the context passed to you will be in the form of a pythonic list with each object in the list having the following structure:\n",
    "\n",
    "{{\n",
    "    \"document_title\": \"the title of the document\",\n",
    "    \"chunk\": \"the chunk of text from the document\",\n",
    "    \"score\": \"the score of the match based on cosine similarity\",\n",
    "    \"locationMetadata\": \"the location metadata if available, else None\",\n",
    "    \"image_document_id\": \"the image document id if available, else None\",\n",
    "}}\n",
    "\n",
    "the pythonic list contains best 10 matches to the user query based on cosine similarity of the embeddings of the user query and the review descriptions.\n",
    "please structure your answers in a very professional manner and in such a way that the user does not get to know that its RAG working under the hood\n",
    "and its as if they are talking to a human. \"\"\"\n",
    "\n",
    "user_prompt = f\"\"\" the user query is: {user_query}\n",
    "the context is : {context}\"\"\"\n",
    "\n",
    "chat_completions_response = azure_openai_client.chat.completions.create(\n",
    "    model = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETIONS_MODEL\"),\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(chat_completions_response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0b6056",
   "metadata": {},
   "source": [
    "### Displaying the Context in PDF Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a85024",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context_item in context:\n",
    "    document_title = context_item.get(\"document_title\")\n",
    "    content_text = context_item.get(\"chunk\")\n",
    "    location_metadata = context_item.get(\"locationMetadata\")\n",
    "    document_title = context_item.get(\"document_title\")\n",
    "\n",
    "    storage_account_url = f\"https://{os.getenv('STORAGE_ACCOUNT_NAME')}.blob.core.windows.net/{os.getenv('STORAGE_ACCOUNT_CONTAINER_NAME')}/{os.getenv('STORAGE_ACCOUNT_FOLDER_NAME')}/\"\n",
    "    highlight_pdf_chunk(\n",
    "            document_title=document_title,\n",
    "            storage_account_url=storage_account_url,\n",
    "            content_text=content_text,\n",
    "            location_metadata=location_metadata\n",
    "        )\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
