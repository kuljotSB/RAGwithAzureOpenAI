{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cfeb078",
   "metadata": {},
   "source": [
    "## AI Search Multi-Modal RAG - Advanced Document Intelligence Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0640439e",
   "metadata": {},
   "source": [
    "![document-intelligence](./Assets/document_intelligence.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397b0dd8",
   "metadata": {},
   "source": [
    "### Installing Required Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbc8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai PyMuPDF requests python-dotenv matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d0a22",
   "metadata": {},
   "source": [
    "### Loading Variables from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c47ab64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "key = os.getenv(\"AZURE_SEARCH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187855d9",
   "metadata": {},
   "source": [
    "### Creating Azure OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d532055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")  \n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_KEY\")\n",
    "\n",
    "azure_openai_client = AzureOpenAI(\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=\"2024-02-15-preview\",\n",
    "    azure_endpoint=azure_openai_endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d3542",
   "metadata": {},
   "source": [
    "### Creating the Embedding Generator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd5b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(client, text):\n",
    "    embedding_model = os.getenv(\"AZURE_OPENAI_EMBEDDING_MODEL\")\n",
    "    \n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model = embedding_model\n",
    "    )\n",
    "    \n",
    "    embeddings=response.model_dump()\n",
    "    return embeddings['data'][0]['embedding']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c88f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"can you tell me something about the invoice which has microsoft fabric implementation on invoice 1?\"\n",
    "vectorised_user_query = generate_embeddings(azure_openai_client, user_query)\n",
    "print(vectorised_user_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bf1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "context=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6354766",
   "metadata": {},
   "source": [
    "### Sending API Call to Azure AI Search Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638ae50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "\n",
    "url = f\"{service_endpoint}/indexes/{index_name}/docs/search?api-version=2023-11-01\"\n",
    "    \n",
    "headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": key\n",
    "    }\n",
    "    \n",
    "body =   {\n",
    "        \"count\": True,\n",
    "        \"select\": \"document_title, content_text, locationMetadata, image_document_id\",\n",
    "        \"vectorQueries\": [\n",
    "            {\n",
    "                \"vector\": vectorised_user_query,\n",
    "                \"k\": 10,\n",
    "                \"fields\": \"content_embedding\",\n",
    "                \"kind\": \"vector\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "response = requests.post(url, headers=headers, data=json.dumps(body))\n",
    "documents = response.json()['value']\n",
    "\n",
    "for doc in documents:\n",
    "    context.append(dict(\n",
    "        {\n",
    "            \"document_title\": doc['document_title'],\n",
    "            \"chunk\": doc['content_text'],\n",
    "            \"score\": doc['@search.score'],\n",
    "            \"locationMetadata\": doc['locationMetadata'] if 'locationMetadata' in doc else None,\n",
    "            \"image_document_id\": doc['image_document_id'] if 'image_document_id' in doc else None\n",
    "        }\n",
    "    ))\n",
    "    \n",
    "for doc in context:\n",
    "    print(doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a9e708",
   "metadata": {},
   "source": [
    "### Function for Location and Displaying Context in the PDF Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e161cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_pdf_chunk(\n",
    "    document_title: str,\n",
    "    storage_account_url: str,\n",
    "    content_text: str = None,\n",
    "    location_metadata: dict = None,\n",
    "    download_dir: str = \".\",\n",
    "    zoom: float = 2.0\n",
    "):\n",
    "    def get_clean_text(text: str) -> str:\n",
    "        # Clean and truncate for search\n",
    "        text = text.replace('\\r', ' ').replace('\\n', ' ').strip()\n",
    "        return ' '.join(text.split()[:20])  # First 20 words\n",
    "\n",
    "    # Build and fetch PDF\n",
    "    pdf_url = f\"{storage_account_url.rstrip('/')}/{document_title}\"\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "    pdf_path = os.path.join(download_dir, document_title)\n",
    "\n",
    "    if not os.path.exists(pdf_path):\n",
    "        try:\n",
    "            response = requests.get(pdf_url)\n",
    "            response.raise_for_status()\n",
    "            if not response.content.startswith(b'%PDF'):\n",
    "                raise ValueError(\"Downloaded file is not a valid PDF.\")\n",
    "            with open(pdf_path, 'wb') as f:\n",
    "                f.write(response.content)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed to download/save PDF: {e}\")\n",
    "            return\n",
    "\n",
    "    try:\n",
    "        doc = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to open PDF: {e}\")\n",
    "        return\n",
    "\n",
    "    img = None\n",
    "    title = \"\"\n",
    "\n",
    "    # ========== LOCATION METADATA ========== #\n",
    "    if location_metadata:\n",
    "        try:\n",
    "            page_number = location_metadata.get(\"pageNumber\", 1) - 1\n",
    "            page = doc.load_page(page_number)\n",
    "            page_width, page_height = page.rect.width, page.rect.height\n",
    "            \n",
    "            print(f\"Page dimensions: {page_width} x {page_height}\")\n",
    "            \n",
    "            bounding_polygons = location_metadata.get(\"boundingPolygons\")\n",
    "            if isinstance(bounding_polygons, str):\n",
    "                bounding_polygons = json.loads(bounding_polygons)\n",
    "            \n",
    "            print(f\"Bounding polygons: {bounding_polygons}\")\n",
    "\n",
    "            # Render page at zoom\n",
    "            mat = fitz.Matrix(zoom, zoom)\n",
    "            pix = page.get_pixmap(matrix=mat)\n",
    "            img = Image.open(BytesIO(pix.tobytes(\"png\")))\n",
    "            draw = ImageDraw.Draw(img)\n",
    "\n",
    "            for poly in bounding_polygons:\n",
    "                # Extract coordinates and handle different coordinate systems\n",
    "                x_vals, y_vals = [], []\n",
    "                for point in poly:\n",
    "                    x = point[\"x\"]\n",
    "                    y = point[\"y\"]\n",
    "                    \n",
    "                    # Check if coordinates appear to be in inches (common for Document Intelligence)\n",
    "                    # Convert inches to points (1 inch = 72 points)\n",
    "                    if x > 1.0:  # Likely in inches\n",
    "                        x_points = x * 72\n",
    "                        y_points = y * 72\n",
    "                        print(f\"Converting from inches: ({x}, {y}) -> ({x_points}, {y_points}) points\")\n",
    "                    else:\n",
    "                        # Assume normalized coordinates\n",
    "                        x_points = x * page_width\n",
    "                        y_points = y * page_height\n",
    "                        print(f\"Using normalized: ({x}, {y}) -> ({x_points}, {y_points}) points\")\n",
    "                    \n",
    "                    x_vals.append(x_points)\n",
    "                    y_vals.append(y_points)\n",
    "\n",
    "                # Get bounding rectangle\n",
    "                x0, y0, x1, y1 = min(x_vals), min(y_vals), max(x_vals), max(y_vals)\n",
    "                \n",
    "                print(f\"Drawing rectangle: ({x0}, {y0}) to ({x1}, {y1})\")\n",
    "                \n",
    "                # Ensure coordinates are within page bounds\n",
    "                x0 = max(0, min(x0, page_width))\n",
    "                y0 = max(0, min(y0, page_height))\n",
    "                x1 = max(0, min(x1, page_width))\n",
    "                y1 = max(0, min(y1, page_height))\n",
    "                \n",
    "                # Draw rectangle with zoom applied\n",
    "                draw.rectangle(\n",
    "                    [x0 * zoom, y0 * zoom, x1 * zoom, y1 * zoom],\n",
    "                    outline=\"red\", width=5\n",
    "                )\n",
    "                \n",
    "                # Add a small text label for debugging\n",
    "                draw.text((x0 * zoom, y0 * zoom - 25), f\"Box {len(x_vals)}\", fill=\"red\")\n",
    "\n",
    "            title = f\"{document_title} - Page {page_number + 1} [via location metadata]\"\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Processing location metadata failed: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            if not content_text:\n",
    "                doc.close()\n",
    "                return\n",
    "\n",
    "    # ========== TEXT SEARCH FALLBACK ========== #\n",
    "    if content_text and img is None:\n",
    "        clean_text = get_clean_text(content_text)\n",
    "        found = False\n",
    "\n",
    "        for page_number in range(len(doc)):\n",
    "            page = doc.load_page(page_number)\n",
    "            matches = page.search_for(clean_text)\n",
    "\n",
    "            if matches:\n",
    "                mat = fitz.Matrix(zoom, zoom)\n",
    "                pix = page.get_pixmap(matrix=mat)\n",
    "                img = Image.open(BytesIO(pix.tobytes(\"png\")))\n",
    "                draw = ImageDraw.Draw(img)\n",
    "\n",
    "                for rect in matches:\n",
    "                    draw.rectangle(\n",
    "                        [rect.x0 * zoom, rect.y0 * zoom, rect.x1 * zoom, rect.y1 * zoom],\n",
    "                        outline=\"blue\", width=3\n",
    "                    )\n",
    "\n",
    "                title = f\"{document_title} - Page {page_number + 1} [via text search]\"\n",
    "                found = True\n",
    "                break\n",
    "\n",
    "        if not found:\n",
    "            print(\"[INFO] Text not found in PDF.\")\n",
    "            doc.close()\n",
    "            return\n",
    "\n",
    "    # ========== DISPLAY OUTPUT ========== #\n",
    "    if img:\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"[ERROR] No image generated for display.\")\n",
    "\n",
    "    doc.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f10835",
   "metadata": {},
   "source": [
    "### Sending Call to GPT Engine for Summarisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e349b200",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"\"\"\"You are meant to behave as a RAG chatbot that derives its context from a database stored in Azure AI Search Solution.\n",
    "please answer strictly from the context from the database provided and if you dont have an answer please politely say so. dont include any extra \n",
    "information that is not in the context and dont include links as well.\n",
    "the context passed to you will be in the form of a pythonic list with each object in the list having the following structure:\n",
    "\n",
    "{{\n",
    "    \"document_title\": \"the title of the document\",\n",
    "    \"chunk\": \"the chunk of text from the document\",\n",
    "    \"score\": \"the score of the match based on cosine similarity\",\n",
    "    \"locationMetadata\": \"the location metadata if available, else None\",\n",
    "    \"image_document_id\": \"the image document id if available, else None\",\n",
    "}}\n",
    "\n",
    "the pythonic list contains best 10 matches to the user query based on cosine similarity of the embeddings of the user query and the review descriptions.\n",
    "please structure your answers in a very professional manner and in such a way that the user does not get to know that its RAG working under the hood\n",
    "and its as if they are talking to a human. \"\"\"\n",
    "\n",
    "user_prompt = f\"\"\" the user query is: {user_query}\n",
    "the context is : {context}\"\"\"\n",
    "\n",
    "chat_completions_response = azure_openai_client.chat.completions.create(\n",
    "    model = os.getenv(\"AZURE_OPENAI_CHAT_COMPLETIONS_MODEL\"),\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ],\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(chat_completions_response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a23a4de",
   "metadata": {},
   "source": [
    "### Displaying the Context in the PDF Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a749a2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for context_item in context:\n",
    "    document_title = context_item.get(\"document_title\")\n",
    "    content_text = context_item.get(\"chunk\")\n",
    "    location_metadata = context_item.get(\"locationMetadata\")\n",
    "    document_title = context_item.get(\"document_title\")\n",
    "\n",
    "    storage_account_url = f\"https://{os.getenv('STORAGE_ACCOUNT_NAME')}.blob.core.windows.net/{os.getenv('STORAGE_ACCOUNT_CONTAINER_NAME')}/{os.getenv('STORAGE_ACCOUNT_FOLDER_NAME')}/\"\n",
    "    highlight_pdf_chunk(\n",
    "            document_title=document_title,\n",
    "            storage_account_url=storage_account_url,\n",
    "            content_text=content_text,\n",
    "            location_metadata=location_metadata\n",
    "        )\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
